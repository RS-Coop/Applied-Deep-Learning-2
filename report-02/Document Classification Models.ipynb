{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bacterial-opening",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smooth-negotiation",
   "metadata": {},
   "source": [
    "We will consider the general task of document classification using a variety of deep neural networks. Specifically, we will consider a binary sentiment classification task on the IMDb movie reviews dataset. We will train three different models for this common task: a simple dense architechture, a convolutional architechture, and a recurrent network architechture. We will then compare the qualities of the three networks to each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-appreciation",
   "metadata": {},
   "source": [
    "The following sources have been used to varying extents.\n",
    "\n",
    "- [Word Embeddings](https://www.tensorflow.org/tutorials/text/word_embeddings)\n",
    "- [Basic Text Classification](https://www.tensorflow.org/tutorials/keras/text_classification)\n",
    "- [RNN Text Classification](https://www.tensorflow.org/tutorials/text/text_classification_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "invisible-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-business",
   "metadata": {},
   "source": [
    "# Loading Data and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-liberia",
   "metadata": {},
   "source": [
    "First, we need to load the dataset we will be using. Much of this process was covered in a separate notebook analyzing the imdb_reviews dataset, so we will move through this without too much discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adjustable-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = {0:'Negative', 1:'Positive'}\n",
    "batch_size = 128 #Batch size for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-newport",
   "metadata": {},
   "source": [
    "When we load the dataset below we take 20% of the training split and set that as the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "modular-cosmetic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to imdb/imdb_reviews/plain_text/1.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "053343bfe2584b1e80184e8a00b61aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88424dd446e047e0a183ba2c21aa4070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-train.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-test.tfrecord...:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised examples...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling imdb_reviews-unsupervised.tfrecord...:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset imdb_reviews downloaded and prepared to imdb/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_ds, val_ds, test_ds = tfds.load('imdb_reviews', data_dir='imdb', \n",
    "                            split=['train[:80%]','train[80%:]','test'],\n",
    "                            as_supervised=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-reservoir",
   "metadata": {},
   "source": [
    "We define a text normalization/standardization function below that will help us clean our input data. The text is converted to lowercase with punctuation and other artifacts like HTML removed. Removing stopwords was considered, but some of the TensorFlow regex functionality seems to be broken which made it more difficult than it was worth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "southeast-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.strings import regex_replace, lower, split, join\n",
    "import re\n",
    "import string\n",
    "# from nltk.corpus import stopwords\n",
    "\n",
    "# sw = stopwords.words('english')\n",
    "\n",
    "def normalize(data):\n",
    "    data = lower(data)\n",
    "    data = regex_replace(data, '<.*?>+', '') #html tags\n",
    "    data = regex_replace(data, '\\[.*?\\]', '') #things in brackets\n",
    "    data = regex_replace(data, 'https?:\\/\\/\\S+|www\\.\\S+', '') #urls\n",
    "    data = regex_replace(data, '\\n', '') #newlines\n",
    "    data = regex_replace(data, '\\w*\\d\\w*', '') #char digit sandwiches\n",
    "    \n",
    "    #Do puncutation at end\n",
    "    data = regex_replace(data, '[%s]' % re.escape(string.punctuation), '')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def removeStopWords(data):\n",
    "    text = join([word for word in split(data) if word not in sw])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-bristol",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-biotechnology",
   "metadata": {},
   "source": [
    "With our dataset mostly ready to go we will move on to building and training our various models. There are a few common tasks we can take care of first: setting hyperparameters and vectorizing our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "light-desperate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cardiovascular-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "embed_dim = 100\n",
    "vocab_size = 1000\n",
    "max_len = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-azerbaijan",
   "metadata": {},
   "source": [
    "We will train for a maximum of 10 epochs, embed our words as 100 dimensional vectors, and only retain the top 1,000 most common words in our vocabulary. In the following code we build a text vectorization layer, which will tokenize our corpus, and apply it to our dataset. We note that we only adapt our vectorizer on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approved-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = layers.experimental.preprocessing.TextVectorization(\n",
    "        standardize=normalize, max_tokens=vocab_size, \n",
    "        output_sequence_length=max_len)\n",
    "\n",
    "vectorizer.adapt(train_ds.map(lambda x,y: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "touched-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(text, label):\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    return vectorizer(text), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "original-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(vectorize_text)\n",
    "val_ds = val_ds.map(vectorize_text)\n",
    "test_ds = test_ds.map(vectorize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passive-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence Length: 500\n",
      "\n",
      "Text: this was an absolutely terrible movie dont be [UNK] in by [UNK] [UNK] or michael [UNK] both are great actors but this must simply be their worst role in history even their great acting could not [UNK] this movies ridiculous storyline this movie is an early [UNK] us [UNK] piece the most [UNK] scenes were those when the [UNK] [UNK] were making their [UNK] for [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] and her [UNK] [UNK] with [UNK] was nothing but a [UNK] emotional [UNK] in a movie that was [UNK] of any real [UNK] i am disappointed that there are movies like this [UNK] actors like [UNK] [UNK] good name i could [UNK] sit through it                                                                                                                                                                                                                                                                                                                                                                                                \n",
      "\n",
      "Label: 0\n"
     ]
    }
   ],
   "source": [
    "vocab = np.array(vectorizer.get_vocabulary())\n",
    "\n",
    "for example, label in train_ds.take(1):\n",
    "    print('Sequence Length: {}\\n'.format(len(example[0])))\n",
    "    text = ' '.join(vocab[example[0]])\n",
    "    print('Text: {}\\n'.format(text))\n",
    "    print('Label: {}'.format(label[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-stand",
   "metadata": {},
   "source": [
    "In the output above we can see the text and label for the first example in our dataset. The '\\[UNK\\]' symbol represents words that were excluded from our vocabulary and are thus unknown. By making our vocabulary size bigger we could include more words, but it seems like the sentiment is preserved in the above example. We also note that the sequence length is reported as 500, but the output string certainly isn't that long. This is happening because the sequences are padded to be as long as the max length sequence, but that padding corresponds to empty strings. We will see that for the dense and recurrent models below this doesn't make a difference, but for the convolutional model it really matters.\n",
    "\n",
    "The last thing we do is setup a callback to stop training if the validation accuracy is plateauing, and set up our dataset for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "collected-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2,\n",
    "                                        mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vocal-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performance configuration\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-bearing",
   "metadata": {},
   "source": [
    "## Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-methodology",
   "metadata": {},
   "source": [
    "Below we define a simple densely connected model. We use a global average pooling layer to deal with the varying sequence lengths, and our final output is a number between 0 and 1 (i.e. our two classes). Essentially we average our input and then run it through a series of densely connected layers to predict one of two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "turned-evans",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         100000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               20200     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 140,401\n",
      "Trainable params: 140,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dense = keras.models.Sequential([\n",
    "    layers.Embedding(vocab_size, embed_dim, mask_zero=True),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(200, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(dense.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-subscriber",
   "metadata": {},
   "source": [
    "We can see that we have about 140,000 parameters, although most of those are from the embedding. We will try to keep this value mostly constant among our different model architechtures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "inner-hardwood",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense.compile(optimizer='Adam',\n",
    "             loss=keras.losses.BinaryCrossentropy(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-sweden",
   "metadata": {},
   "source": [
    "Our loss function is binary crossentropy as we are only considering two classes. Next we train..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sought-contrary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 6s 30ms/step - loss: 0.6202 - accuracy: 0.6439 - val_loss: 0.3542 - val_accuracy: 0.8472\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 4s 27ms/step - loss: 0.3492 - accuracy: 0.8517 - val_loss: 0.3405 - val_accuracy: 0.8552\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.3285 - accuracy: 0.8656 - val_loss: 0.3424 - val_accuracy: 0.8568\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.3219 - accuracy: 0.8686 - val_loss: 0.3444 - val_accuracy: 0.8568\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.3171 - accuracy: 0.8695 - val_loss: 0.3441 - val_accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "d_history = dense.fit(train_ds, validation_data=val_ds, epochs=epochs,\n",
    "                     callbacks=[monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "final-procurement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 4s 21ms/step - loss: 0.3400 - accuracy: 0.8536\n",
      "0.853600025177002\n"
     ]
    }
   ],
   "source": [
    "_, d_acc = dense.evaluate(test_ds)\n",
    "print(d_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southern-seeker",
   "metadata": {},
   "source": [
    "We see that we only ended up training for a few of the possible 10 epochs as are validation accuracy quickly plateaued. On the test set it looks like we achieved around 85% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-jenny",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "searching-custody",
   "metadata": {},
   "source": [
    "A convolutional network is defined below. In this case specifying the input sequence length was very important. Without it the model would take an incredibly long time to train, and I am not quite sure why. Our model consists of a series of convolutional layers with a dense classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "suburban-infrared",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 100)          100000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 500, 32)           6432      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 64)           6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 250, 72)           9288      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 72)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 250)               18250     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 140,429\n",
      "Trainable params: 140,429\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cnn = keras.models.Sequential([\n",
    "    layers.Embedding(vocab_size, embed_dim, input_length=500),\n",
    "    layers.Conv1D(32, 2, activation='relu', padding='same'),\n",
    "    layers.Conv1D(64, 3, activation='relu', padding='same'),\n",
    "    layers.MaxPooling1D(),\n",
    "    layers.Conv1D(72, 2, activation='relu', padding='same'),\n",
    "    layers.GlobalAveragePooling1D(),\n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-messenger",
   "metadata": {},
   "source": [
    "Again we point out the we are trying to keep our parameters constant around 140,000. Everything else stays the same as we train our network..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "alien-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='Adam',\n",
    "             loss=keras.losses.BinaryCrossentropy(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nutritional-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 32s 123ms/step - loss: 0.6379 - accuracy: 0.5846 - val_loss: 0.3784 - val_accuracy: 0.8410\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 8s 51ms/step - loss: 0.3607 - accuracy: 0.8498 - val_loss: 0.3629 - val_accuracy: 0.8496\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 8s 51ms/step - loss: 0.3349 - accuracy: 0.8597 - val_loss: 0.3451 - val_accuracy: 0.8570\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 8s 51ms/step - loss: 0.3163 - accuracy: 0.8676 - val_loss: 0.3394 - val_accuracy: 0.8576\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 8s 51ms/step - loss: 0.3056 - accuracy: 0.8698 - val_loss: 0.3370 - val_accuracy: 0.8594\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 8s 51ms/step - loss: 0.2997 - accuracy: 0.8744 - val_loss: 0.3372 - val_accuracy: 0.8590\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 8s 51ms/step - loss: 0.2929 - accuracy: 0.8776 - val_loss: 0.3379 - val_accuracy: 0.8598\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 8s 51ms/step - loss: 0.2878 - accuracy: 0.8810 - val_loss: 0.3396 - val_accuracy: 0.8596\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 8s 52ms/step - loss: 0.2832 - accuracy: 0.8833 - val_loss: 0.3446 - val_accuracy: 0.8578\n"
     ]
    }
   ],
   "source": [
    "c_history = cnn.fit(train_ds, validation_data=val_ds, epochs=epochs,\n",
    "                   callbacks=[monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "nonprofit-tiger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 7s 35ms/step - loss: 0.3356 - accuracy: 0.8577\n",
      "0.8576800227165222\n"
     ]
    }
   ],
   "source": [
    "_, c_acc = cnn.evaluate(test_ds)\n",
    "print(c_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-fourth",
   "metadata": {},
   "source": [
    "This time we trained a few epochs longer but only achieved about the same training accuracy of 85%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-learning",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-democrat",
   "metadata": {},
   "source": [
    "Our last model is a recurrent neural network, where we are specifically using GRU layers. We have two stacked GRUs and then a dense classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "foster-narrow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 100)         100000    \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, None, 61)          29829     \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 20)                4980      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 250)               5250      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 140,310\n",
      "Trainable params: 140,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rnn = keras.models.Sequential([\n",
    "    layers.Embedding(vocab_size, embed_dim, mask_zero=True),\n",
    "    layers.GRU(61, return_sequences=True),\n",
    "    layers.GRU(20),\n",
    "    layers.Dense(250, activation='relu'),\n",
    "    layers.Dropout(0.2),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "print(rnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-slovenia",
   "metadata": {},
   "source": [
    "Roughly 140,000 parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "general-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.compile(optimizer='Adam',\n",
    "             loss=keras.losses.BinaryCrossentropy(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "minor-circle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "157/157 [==============================] - 25s 127ms/step - loss: 0.6495 - accuracy: 0.5781 - val_loss: 0.4427 - val_accuracy: 0.7910\n",
      "Epoch 2/10\n",
      "157/157 [==============================] - 18s 113ms/step - loss: 0.5099 - accuracy: 0.7527 - val_loss: 0.4319 - val_accuracy: 0.8128\n",
      "Epoch 3/10\n",
      "157/157 [==============================] - 18s 114ms/step - loss: 0.4044 - accuracy: 0.8266 - val_loss: 0.3655 - val_accuracy: 0.8384\n",
      "Epoch 4/10\n",
      "157/157 [==============================] - 18s 114ms/step - loss: 0.3401 - accuracy: 0.8573 - val_loss: 0.3577 - val_accuracy: 0.8412\n",
      "Epoch 5/10\n",
      "157/157 [==============================] - 18s 114ms/step - loss: 0.3071 - accuracy: 0.8743 - val_loss: 0.3508 - val_accuracy: 0.8470\n",
      "Epoch 6/10\n",
      "157/157 [==============================] - 18s 115ms/step - loss: 0.2935 - accuracy: 0.8796 - val_loss: 0.3448 - val_accuracy: 0.8508\n",
      "Epoch 7/10\n",
      "157/157 [==============================] - 18s 115ms/step - loss: 0.2818 - accuracy: 0.8863 - val_loss: 0.3391 - val_accuracy: 0.8542\n",
      "Epoch 8/10\n",
      "157/157 [==============================] - 18s 115ms/step - loss: 0.2690 - accuracy: 0.8928 - val_loss: 0.3401 - val_accuracy: 0.8542\n",
      "Epoch 9/10\n",
      "157/157 [==============================] - 18s 115ms/step - loss: 0.2581 - accuracy: 0.8970 - val_loss: 0.3507 - val_accuracy: 0.8496\n"
     ]
    }
   ],
   "source": [
    "r_history = rnn.fit(train_ds, validation_data=val_ds, epochs=epochs,\n",
    "                   callbacks=[monitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "stock-europe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196/196 [==============================] - 9s 45ms/step - loss: 0.3361 - accuracy: 0.8623\n",
      "0.8623200058937073\n"
     ]
    }
   ],
   "source": [
    "_, r_acc = rnn.evaluate(test_ds)\n",
    "print(r_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-nurse",
   "metadata": {},
   "source": [
    "Slightly better than our other models with 86% accuracy on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "official-wireless",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "subject-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-skirt",
   "metadata": {},
   "source": [
    "Before we get to some more quantitative analysis we will note a few qualitative things. First, all the networks seem to have achieved very comparable performance. Second, the dense network trained the fastest and the recurrent network trained the slowest by far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-cyprus",
   "metadata": {},
   "source": [
    "- plot relative accuracies\n",
    "- comment on training time and parameters\n",
    "- look at embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ready-commissioner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,8))\n",
    "plot = sns.barplot(x=['Dense', 'CNN', 'RNN'], y=[d_acc, c_acc, r_acc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-terror",
   "metadata": {},
   "source": [
    "Well thats not a very interesting graph because they all did so similar in performance. The last thing I am interested in is looking at how the learned embeddings vary across the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "understanding-exploration",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_embed = dense.layers[0]\n",
    "c_embed = cnn.layers[0]\n",
    "r_embed = rnn.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "metallic-closing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(83, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "s = vectorizer(['bad'])\n",
    "print(s[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "reported-alcohol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bad'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[83]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-siemens",
   "metadata": {},
   "source": [
    "We have ectracted the embedding layers from each network and taken the sample word (the 497th word in our vocab) bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "objective-gothic",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = [d_embed(s)[0,0,:], c_embed(s)[0,0,:], r_embed(s)[0,0,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "funky-psychiatry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance Dense and CNN: 1.7357908487319946\n",
      "Distance Dense and RNN: 1.6810531616210938\n",
      "Distance CNN and RNN: 1.4131357669830322\n"
     ]
    }
   ],
   "source": [
    "print('Distance Dense and CNN: {}'.format(tf.norm(embeds[0]-embeds[1])))\n",
    "print('Distance Dense and RNN: {}'.format(tf.norm(embeds[0]-embeds[2])))\n",
    "print('Distance CNN and RNN: {}'.format(tf.norm(embeds[1]-embeds[2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-grain",
   "metadata": {},
   "source": [
    "The embeddings are different as we would expect, but not too different. It would be more interesting to look at the differences using something like t-SNE, but I will save that for another time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-reset",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-dominican",
   "metadata": {},
   "source": [
    "In this notebook I looked at text-based binary setiment classification using three different neural network architechtures. The models I considered were quite simple, but I learned a lot in the process and I have a few major takeaways. First, in this case performance did not vary across model architechture. Based on my outside knowledge this implies that I need to be more nuanced about how I build my models, or that at this small scale variations are not visible. It is clear that recurrent models are much slower to train which can be a big downside. Second, it makes sense to use a pre-trained embedding for many tasks like the one considered here. Learning an embedding will only take time, resources (i.e. parameters), and will probably leave out some words. In the future I will use such an embedding trained an a very large corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
